{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d98ad7c",
   "metadata": {},
   "source": [
    "# CA3 model\n",
    "\n",
    "This notebook is for building out the CA3 model as previous implementation doesn't work.\n",
    "\n",
    "Formula is:\n",
    "$$\n",
    "min_{\\vec{w}_{x_1}, \\vec{w}_{x_2}, \\vec{w}_a, \\vec{w}_b} \\left( -\\vec{w}_{x_1}^T S_{xa} \\vec{w}_a - \\vec{w}_{x_2}^T S_{xb} \\vec{w}_b + \\sum_{i \\in \\{x_1, x_2, a, b\\}} \\frac{1}{2} \\lambda_i \\left( \\vec{w}_i^T S_{ii} \\vec{w}_i - 1 \\right) + \\theta_{rr}(\\vec{w}_{x_1}, \\vec{w}_{x_2}) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0861b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemmr.generative_model import GEMMR\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d9b9d",
   "metadata": {},
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c38d98",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 200\n",
    "n_features_x = 10\n",
    "n_features_y = 8\n",
    "\n",
    "# Latent variables (shared source of variance)\n",
    "latent = np.random.randn(n_samples, 3)\n",
    "\n",
    "# Mix latent variables with some noise\n",
    "behavioural_data_study1 = latent @ np.random.randn(3, n_features_x) + 0.1 * np.random.randn(n_samples, n_features_x)\n",
    "imging_data_study1 = latent @ np.random.randn(3, n_features_y) + 0.1 * np.random.randn(n_samples, n_features_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cf757017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition = GEMMR('cca', wx=2, wy=50, r_between=0.3)\n",
    "behavioural_data_study1, imging_data_study1 = model_definition.generate_data(n=200)\n",
    "behavioural_data_study2, imging_data_study2 = model_definition.generate_data(n=190)\n",
    "study1 = (imging_data_study1, behavioural_data_study1) \n",
    "study2 = (imging_data_study2, behavioural_data_study2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5dfb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gemmr.estimators import SVDCCA\n",
    "cca = SVDCCA().fit_transform(imging_data_study1, behavioural_data_study1)\n",
    "len(cca[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30dd3d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.008702029962619288)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2= []\n",
    "for val in range(imging_data_study1.shape[1]):\n",
    "    corr = scipy.stats.pearsonr(behavioural_data_study1[:, 1], imging_data_study1[:, val])[0]\n",
    "    r2.append(corr)\n",
    "np.mean(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc9559",
   "metadata": {},
   "source": [
    "## Step 1: Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523234c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function to demean data.\n",
    "\n",
    "    Parmeteres\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        data to demean\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: array\n",
    "        demeaned data\n",
    "    \"\"\"\n",
    "    return data - data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0a8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_cov(matrix_1: np.ndarray, matrix_2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function to calculate \n",
    "    covariance matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix_1: np.ndarray\n",
    "        A matrix tht should \n",
    "        correspond to subject by \n",
    "        features\n",
    "    matrix_2: np.ndarray\n",
    "        A matrix that should \n",
    "        correspond to features by\n",
    "        feautres \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray: array\n",
    "        array of cross covariance matrix\n",
    "    \"\"\"\n",
    "    return (matrix_1.T @ matrix_2) / matrix_1.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54813454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_able_to_process(study_pair: tuple, behav_data: np.ndarray, img_data: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Function to check that data\n",
    "    is in correct format to be processed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "     study_pair: tuple, \n",
    "         tuple of behavioural data \n",
    "         and imging data\n",
    "     behav_data: np.ndarray\n",
    "         array of behav_data \n",
    "     img_data: np.ndarray\n",
    "         array of img_data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool: boolean\n",
    "        bool of if failed or not\n",
    "    \"\"\"\n",
    "    if not isinstance(study_pair, (tuple, list)) or len(study_pair) != 2:\n",
    "        print(\"Given argument isn't a pair of datasets\")\n",
    "        return False\n",
    "    if not isinstance(behav_data, np.ndarray) or not isinstance(img_data, np.ndarray):\n",
    "        print(\"Data provided isn't a numpy array\")\n",
    "        return False\n",
    "    if behav_data.shape[0] == 0 or img_data.shape[0] == 0 or behav_data.shape[0] != img_data.shape[0]:\n",
    "        print(f\"Mismatch between ({behav_data.shape[0]} and {img_data.shape[0]})\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb76963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance_matricies(*study_pairs) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates covariance matrices and auto covariance\n",
    "    matricies\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    study_pairs: tuple\n",
    "        a tuple or list containing two numpy arrays:\n",
    "        (behavioural_data, imaging_data).\n",
    "        Assumes data is (subjects x features).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    covariance_results: dict\n",
    "        dictionary of covariance and auto-covariance matrices\n",
    "\n",
    "    \"\"\"\n",
    "    covariance_results = {}\n",
    "    for idx, study_pair in enumerate(study_pairs):\n",
    "        behav_data, img_data = study_pair\n",
    "        if not data_able_to_process(study_pair, behav_data, img_data):\n",
    "            continue\n",
    "        behav_data = mean_center(behav_data)\n",
    "        img_data = mean_center(img_data)\n",
    "        study_num = idx + 1\n",
    "        try:\n",
    "            covariance_results[f\"s_behav{study_num}_behav{study_num}\"] = cross_cov(behav_data, behav_data)\n",
    "            covariance_results[f\"s_img{study_num}_img{study_num}\"] = cross_cov(img_data, img_data)\n",
    "            covariance_results[f\"s_img{study_num}_behav{study_num}\"] = cross_cov(img_data, behav_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating covariances for Study {study_num}: {e}\")\n",
    "            return None\n",
    "    return covariance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd37f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_mat = calculate_covariance_matricies(study1, study2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36418b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_x1a = cross_cov(behavioural_data_study1, imging_data_study1)\n",
    "s_x2b = cross_cov(behavioural_data_study2, imging_data_study2)\n",
    "s_x1x1 = cross_cov(behavioural_data_study1, behavioural_data_study1)\n",
    "s_x2x2 = cross_cov(behavioural_data_study2, behavioural_data_study2)\n",
    "s_aa = cross_cov(imging_data_study1, imging_data_study1)\n",
    "s_bb = cross_cov(imging_data_study2, imging_data_study2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040469c",
   "metadata": {},
   "source": [
    "## Step 2. Intialization of weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9220d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_intialization(*weights) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Define a set of random starting \n",
    "    weights\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights: tuple(int)\n",
    "        tuple of set amount\n",
    "        of int values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarrray\n",
    "        array of numpy values\n",
    "    \"\"\"\n",
    "    return np.random.randn(sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d329c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = {\n",
    "  '1': behavioural_data_study1.shape[1], \n",
    "   '2': behavioural_data_study2.shape[1],\n",
    "    '3': imging_data_study1.shape[1],\n",
    "    '4': imging_data_study2.shape[1]\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c66dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0 = weight_intialization(\n",
    "    behavioural_data_study1.shape[1], \n",
    "    behavioural_data_study2.shape[1],\n",
    "    imging_data_study1.shape[1],\n",
    "    imging_data_study2.shape[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b44fd",
   "metadata": {},
   "source": [
    "## Step 3. Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2db5333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx1_shape = s_x1x1.shape[0]\n",
    "dx2_shape = s_x2x2.shape[0]\n",
    "da_shape = s_aa.shape[0]\n",
    "db_shape = s_bb.shape[0]\n",
    "dx_shape = dx1_shape + dx2_shape\n",
    "dac_shape =  dx_shape + da_shape\n",
    "\n",
    "def get_dimensions(s_x1x1, s_x2x2, s_aa):\n",
    "    dx1_shape = s_x1x1.shape[0]\n",
    "    dx2_shape = s_x2x2.shape[0]\n",
    "    da_shape = s_aa.shape[0]\n",
    "    dx_shape =  dx1_shape + dx2_shape\n",
    "    return {\n",
    "        'dx1_shape': dx1_shape,\n",
    "        'dx_shape' : dx_shape,\n",
    "        'dac_shape':  dx_shape + da_shape\n",
    "    }\n",
    "\n",
    "def get_weights(weight_array, dx1_shape, dx_shape, dac_shape):\n",
    "    return {\n",
    "        \"wx1\": weight_array[:dx1_shape],\n",
    "        \"wx2\": weight_array[dx1_shape:dx_shape],\n",
    "        \"wa\": weight_array[dx_shape:dac_shape],\n",
    "        \"wb\": weight_array[dac_shape:]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43838fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_cov_term(weight_beh, cov_mat, weight_img):\n",
    "    return -weight_beh.T @ cov_mat @ weight_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a0332f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization_term(weight, cov_mat):\n",
    "    return 0.5 * 1.0 * (weight.T @ cov_mat @ weight - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeeb8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity_penality(theta_r, img_weight1, img_weight2):\n",
    "    return 0.5 * theta_r * np.sum((img_weight1 - img_weight2) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c79bec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(weights, s_x1a, s_x2b, s_x1x1, s_x2x2, s_aa, s_bb, theta_r):\n",
    "    dimensions = get_dimensions(s_x1x1, s_x2x2, s_aa)\n",
    "    weights = get_weights(\n",
    "            weights, \n",
    "            dimensions['dx1_shape'], \n",
    "            dimensions['dx_shape'], \n",
    "            dimensions['dac_shape'])\n",
    "    term1 = cross_cov_term(weights['wx1'],s_x1a, weights['wa'])\n",
    "    term2 = cross_cov_term(weights['wx2'],s_x2b, weights['wb'])\n",
    "    reg_x1 = regularization_term(weights['wx1'], s_x1x1)\n",
    "    reg_x2 = regularization_term(weights['wx2'], s_x2x2)\n",
    "    reg_a = regularization_term(weights['wa'], s_aa)\n",
    "    reg_b = regularization_term(weights['wb'], s_bb)\n",
    "    theta_r = dissimilarity_penality(theta_r, weights['wa'], weights['wb'])\n",
    "    return term1 + term2 + reg_x1 + reg_x2 + reg_a + reg_b + theta_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f9f1c9",
   "metadata": {},
   "source": [
    "## Step 4: Minimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee3de1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "Best θ_r: 0.1668100537200059\n",
      "Best loss: -1.9999999932695567\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "optimal_theta_r = None\n",
    "optimium_model = None\n",
    "\n",
    "for theta_r in np.logspace(-3, 2, 10):\n",
    "    weights_0 = weight_intialization(\n",
    "        behavioural_data_study1.shape[1], \n",
    "        behavioural_data_study2.shape[1],\n",
    "        imging_data_study1.shape[1],\n",
    "        imging_data_study2.shape[1])  # re-init each time\n",
    "    res = minimize(\n",
    "        objective_function,\n",
    "        weights_0,\n",
    "        args=(s_x1a, s_x2b, s_x1x1, s_x2x2, s_aa, s_bb, theta_r),\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "    if res.status !=0:\n",
    "        print(res.status)\n",
    "        continue\n",
    "\n",
    "\n",
    "    if res.fun < best_loss:\n",
    "        best_loss = res.fun\n",
    "        best_theta_r = theta_r\n",
    "        optimium_model = res\n",
    "\n",
    "print(f\"Best θ_r: {best_theta_r}\")\n",
    "print(f\"Best loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c531d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: RELATIVE REDUCTION OF F <= FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: -1.9999999932695567\n",
       "        x: [-4.030e-05  7.906e-06 ...  1.845e-06 -2.273e-04]\n",
       "      nit: 50\n",
       "      jac: [-4.192e-05 -4.485e-06 ... -5.773e-07 -3.841e-06]\n",
       "     nfev: 5775\n",
       "     njev: 55\n",
       " hess_inv: <104x104 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimium_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5635b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = get_dimensions(s_x1x1, s_x2x2, s_aa)\n",
    "weights = get_weights(optimium_model.x,\n",
    "            dimensions['dx1_shape'], \n",
    "            dimensions['dx_shape'], \n",
    "            dimensions['dac_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d427de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get projections (scores)\n",
    "scores_x1 = behavioural_data_study1 @ weights['wx1']\n",
    "scores_x2 = behavioural_data_study2 @ weights['wx2']\n",
    "scores_a  = imging_data_study1 @ weights['wa']\n",
    "scores_b  = imging_data_study2 @ weights['wb']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac5b74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.032719708577966966)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.012496034191626546)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.5478433431911584e-05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(np.corrcoef(scores_x1, scores_a)[0, 1])\n",
    "display(np.corrcoef(scores_x2, scores_b)[0, 1])\n",
    "display(np.linalg.norm(weights['wa'] - weights['wb']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cfca62",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8c072048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CA3:\n",
    "    def __init__(self, theta: float=None):\n",
    "        self.theta_ = np.logspace(-3, 2, 10) if theta is None else theta\n",
    "        self.intial_weights_ = None\n",
    "        self.dims_ = []\n",
    "        self.best_loss = float('inf')\n",
    "        self.optimal_theta_r = None\n",
    "        self.weights_ = None\n",
    " \n",
    "\n",
    "    def fit(self, *data_sets):\n",
    "        self.covariances_ = calculate_covariance_matricies(*data_sets)\n",
    "        self.dims_ = self._get_dimensions(*data_sets)\n",
    "        self.intial_weights_ = weight_intialization(*list(itertools.chain(*self.dims_)))\n",
    "        self._optimise()\n",
    "\n",
    "    def transform(self, *data_sets):\n",
    "        assert self.weights_ is not None, \"Model must be fitted before transfomed can be called.\"\n",
    "        assert len(data_sets) == len(self.dims_), \"Model fitted with different number of datasets.\"\n",
    "\n",
    "        scores = []\n",
    "        correlations = []\n",
    "    \n",
    "        for (X_img, X_behav), (wx, wb) in zip(data_sets, self.weights_):\n",
    "            # Project to canonical components\n",
    "            print(wx)\n",
    "            u = X_img @ wx\n",
    "            v = X_behav @ wb\n",
    "            scores.append((u, v))\n",
    "    \n",
    "            # Correlation coefficients per component\n",
    "            corr = np.array([np.corrcoef(u[:, i], v[:, i])[0, 1] for i in range(u.shape[1])])\n",
    "            correlations.append(corr)\n",
    "    \n",
    "        return correlations, scores\n",
    " \n",
    "            \n",
    "    def _optimise(self):\n",
    "        if isinstance(self.theta_, (list, np.ndarray)):\n",
    "            for theta in self.theta_:\n",
    "                model = self._optimising_model(theta)\n",
    "                if model.status !=0:\n",
    "                    continue\n",
    "                if model.fun < self.best_loss:\n",
    "                    self.best_loss = model.fun\n",
    "                    self.optimal_theta_r = theta\n",
    "                    self.weights_ = self._split_weights(model.x)\n",
    "        else:\n",
    "            model = self._optimising_model(theta)\n",
    "            self.best_loss = model.fun\n",
    "            self.optimal_theta_r = theta\n",
    "            self.weights_ = self._split_weights(model.x)\n",
    "\n",
    "\n",
    "    def _optimising_model(self, theta):\n",
    "        return minimize(\n",
    "            self._objective_function,\n",
    "            self.intial_weights_,\n",
    "            args=(self.covariances_, theta),\n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "    \n",
    "    def _get_dimensions(self, *data_sets):\n",
    "        return [(behav.shape[1], img.shape[1]) for behav, img in data_sets]\n",
    "\n",
    "    \n",
    "    def _split_weights(self, w):\n",
    "        \"\"\"\n",
    "        Splits the flat weight vector w into individual vectors\n",
    "        for each behavioural and imaging dataset.\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        weights = []\n",
    "        for behav_dim, img_dim in self.dims_:\n",
    "            wx = w[offset:offset + img_dim]\n",
    "            offset += img_dim\n",
    "            wb = w[offset:offset + behav_dim]\n",
    "            offset += behav_dim\n",
    "            weights.append((wx, wb))\n",
    "        return weights\n",
    "    \n",
    "    def _objective_function(self, weights, covariances, theta):\n",
    "        total_loss = 0\n",
    "        weights_ = self._split_weights(weights)\n",
    "        for idx, (wx, wb) in enumerate(weights_):\n",
    "\n",
    "            s_xb = covariances[f\"s_img{idx+1}_behav{idx+1}\"]\n",
    "            s_xx = covariances[f\"s_img{idx+1}_img{idx+1}\"]\n",
    "            s_bb = covariances[f\"s_behav{idx+1}_behav{idx+1}\"]\n",
    "    \n",
    "            total_loss += cross_cov_term(wx, s_xb, wb) \n",
    "            total_loss += regularization_term(wx, s_xx)\n",
    "            total_loss += regularization_term(wb, s_bb)\n",
    "    \n",
    "        # Similarity penalty across imaging weights\n",
    "        if theta > 0 and len(weights_) > 1:\n",
    "            for img_data in range(len(weights_)):\n",
    "                for next_img_data in range(img_data + 1, len(weights_)):\n",
    "                    total_loss += dissimilarity_penality(theta, weights_[img_data][0], weights_[next_img_data][0])\n",
    "    \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5254108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca3 = CA3()\n",
    "ca3.fit(study1, study2)\n",
    "#ca3.transform(study1, study2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0fbfd701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.08737774e-05 -1.13659419e-05]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mca3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[165], line 27\u001b[0m, in \u001b[0;36mCA3.transform\u001b[0;34m(self, *data_sets)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (X_img, X_behav), (wx, wb) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_sets, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Project to canonical components\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(wx)\n\u001b[0;32m---> 27\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43mX_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwx\u001b[49m\n\u001b[1;32m     28\u001b[0m     v \u001b[38;5;241m=\u001b[39m X_behav \u001b[38;5;241m@\u001b[39m wb\n\u001b[1;32m     29\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend((u, v))\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 50)"
     ]
    }
   ],
   "source": [
    "ca3.transform(study1, study2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cea414ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 50)\n",
      "(50,)\n",
      "(190, 50)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "for (X_img, X_behav), (wx, wb) in zip((study1, study2), ca3.weights_):\n",
    "    print(X_img.shape)\n",
    "    print(wb.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
